---
## Change the name of the resource
## Default: use the chart name
# nameOverride:

pod:
  kubectl:
    ## The image used for the kubectl container in this pod
    ## Ref: https://quay.io/repository/littlemanco/kubectl
    image: "quay.io/littlemanco/kubectl:v1.6.0-2"
    ## More generally, a "request" can be thought of as "how much is this container expected to need usually". it should
    ## be possible to burst outside these constraints (during a high load operation). However, Kubernetes may kill the
    ## pod if the node is under too higher load and the burst is outside its request
    ##
    ## Limits are hard limits. Violating them is either impossible, or results in container death. I'm not sure whether
    ## making these optional is a good idea or not; at the moment, I think I'm happy to defer QOS to the cluster and try
    ## and keep requests close to usage.
    ##
    ## Requests are what are used to determine whether more software "fits" onto the cluster.
    ##
    ## Ref: http://kubernetes.io/docs/user-guide/compute-resources/
    ## Ref: https://github.com/kubernetes/kubernetes/blob/master/docs/design/resource-qos.md
    ## Ref: https://docs.docker.com/engine/reference/run/#/runtime-constraints-on-resources
    resources:
      requests:
        ## How much CPU this container is expected to need
        cpu: "10m"
        ## How much memory this container is expected to need.
        memory: "24Mi"
      limits:
        ## The max CPU this container should be allowed to use
        # cpu: "100m"
        ## The max memory this container should be allowed to use. Note: If a container exceeds its memory limit,
        ## it may terminated.
        # memory: "512Mi"
  linkerd:
    ## See kubectl.image
    image: "buoyantio/linkerd:0.9.1-32b"
    ## See kubectl.resources
    resources:
      requests:
        cpu: "100m"
        memory: "128Mi"

## Monitoring adds the prometheus.io annotations to pods and services, so that the Prometheus Kubernetes SD mechanism
## as configured in the examples will automatically discover both the pods and the services to query.
##
## This defaults on, as the annotations should do no harm where Prometheus is not available but will automatically
## expose the application where Prometheus is.
##
## See https://github.com/prometheus/docs/blob/master/content/docs/operating/configuration.md
## See https://github.com/prometheus/prometheus/blob/master/documentation/examples/prometheus-kubernetes.yml
monitoring:
  ## Whether to scrape this service with the montoring toolkit. Mostly useful for blackbox probing of a given service
  ## to ensure it's "up"
  service:
    ## monitoring should be configured to only scrape services that have a value of "true"
    scrape: "true"
    ## probe this endpoint with the blackbox probe
    probe: "true"
    ## Path on which metrics are exposed
    path: "/admin/metrics/prometheus"
